{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9. 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 잠재 요인 협업 필터링\n",
    "\n",
    "p564(583)~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 잠재 요인 협업 필터링의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 잠재 요인 협업 필터링 (Lanent Factor Collaborative Filtering)\n",
    "\n",
    "- 사용자-아이템 평점 매트릭스 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 행렬 분해 (Matrix Factorization)\n",
    "\n",
    "- 대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 **분해**하는 과정에서 잠재 요인을 추출\n",
    "- 이러한 기법을 행렬 분해라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 행렬 분해 기반의 잠재 요인 협업 필터링\n",
    "\n",
    "- 넷플릭스 경연 대회에서 사용되면서 유명해짐\n",
    "- 우승을 차지한 모델은 행렬 분해 기반의 여러 모델을 결합해 만든 모델\n",
    "- 이후 많은 추천 시스템이 행렬 분해에 기반한 잠재 요인 협업 필터링을 적용하고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 잠재 요인\n",
    "\n",
    "- 잠재 요인 협업 필터링은 사용자-아이템 평점 행렬 데이터만을 이용해 말 그대로 **'잠재 요인'**을 끄집어 내는 것을 의미\n",
    "- '잠재 요인'이 어떤 것인지는 명확히 정의할 수 없다.\n",
    "- 하지만 이러한 '잠재 요인'을 기반으로 다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재 요인 행렬과 아이템-잠재 요인 행렬의 전치 행렬(즉, 잠재요인-아이템 행렬)로 분해\n",
    "\n",
    "> **사용자-아이템 행렬 (다차원 희소 행렬)**  \n",
    "  $\\rightarrow$ 사용자-잠재 요인 행렬 (저차원 밀집 행렬)  \n",
    "  $\\rightarrow$ 잠재 요인-아이템 행렬 (아이템-잠재 요인 행렬의 전치 행렬)\n",
    "- 이렇게 분해된 두 행렬의 내적을 통해 새로운 사용자-아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않는 아이템에 대한 예측 평점을 생성하는 것이 잠재 요인 협력 필터링 알고리즘의 주 내용이다.  \n",
    "  \n",
    "  \n",
    "- 다음 그림은 이러한 행렬 분해 기법을 이용해 사용자-잠재 요인 행렬과 아이템-잠재 요인 행렬의 전치행렬로 분해된 데이터 세트를 다시 내적 곱으로 결합하면서 사용자가 예측하지 않은 아이템에 대한 평점을 도출하는 방식을 개략적으로 나타낸 것이다.\n",
    "\n",
    "<img src=\"images/Ch09/04/img001.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 영화 평점 기반의 사용자-아이템 평점 행렬 데이터의 잠재 요인\n",
    "\n",
    "- 영화가 가지는 장르별 특성 선호로도 가정\n",
    "  - 사용자-잠재 요인 행렬 : 사용자의 영화 장르에 대한 선호도\n",
    "  - 아이템-잠재 요인 행렬 : 영화의 장르별 특성값    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 사용자-아이템 평점 행렬 내적 계산 과정\n",
    "\n",
    "- 다음 그림을 수식을 통해 살펴 보자\n",
    "\n",
    "<img src=\"images/Ch09/04/img002.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**수식**\n",
    "\n",
    "- $R(u, i) = P(u,k) \\cdot Q^T(k,i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6.1 $R(u, i)$\n",
    "\n",
    "- 사용자-아이템 평점 행렬 $R$에서 사용자(User)의 아이템(Item)에 대한 평점 행렬\n",
    "- $u$ : 사용자 아이디\n",
    "- $i$ : 아이템 아이디\n",
    "- $R(1, 1)$ = 4\n",
    "- $R(1, 4)$ = 2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6.2 $P(u,k)$\n",
    "\n",
    "- 사용자-잠재 요인 행렬\n",
    "- 사용자의 영화 장르별 선호도 행렬\n",
    "- factor 1 : 액션(Action) 선호도\n",
    "- factor 2 : 로맨스(Romance) 선호도\n",
    "- 설명상 편의를 위해 세상에 영화 장르가 액션과 로맨스밖에 없다고 가정\n",
    "- $P(u, k)$\n",
    "  - $u$ : 사용자 아이디\n",
    "  - $k$ : 잠재 요인 컬럼인 장르별 선호도\n",
    "- $P(1, 1)$ = 0.94\n",
    "- $P(1, 2)$ = 0.96  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6.3 $Q(i,k)$\n",
    "\n",
    "- 아이템-잠재 요인 행렬\n",
    "- 영화별로 여러 장르 요소로 구성된 영화의 장르별 요소 행렬\n",
    "- factor 1 : 영화의 Action 요소 값\n",
    "- factor 2 : 영화의 Romance 요소 값\n",
    "- $Q(i, k)$\n",
    "  - $i$ : 아이템 아이디\n",
    "  - $k$ : 잠재 요인 컬럼인 장르별 요소  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6.4 내적 계산    \n",
    "    \n",
    "- $Q$와 $P$의 내적 계산을 통해 예측 평점을 계산하기 위해 $Q$의 행과 열 위치를 서로 교환한 $Q.T$로 변환\n",
    "  - $Q(i, k)$ $\\rightarrow$ $Q.T(k, i)$\n",
    "  - $Q.T(1, 1)$ = 1.7\n",
    "  - $Q.T(2, 1)$ = 2.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6.5 계산 방법 설명\n",
    "\n",
    "- 평점이란 **사용자의 특정 영화 장르에 대한 선호도**와 **개별 영화의 그 장르적 특성값**을 반영해 결정된다.\n",
    "  - ex) 사용자가 액션 영화를 매우 좋아하고, 특정 영화가 액션 영화의 특성이 매우 크다  \n",
    "  $\\rightarrow$ 사용자가 해당 영화에 높은 평점을 줄 것이다.  \n",
    "  \n",
    "  \n",
    "- 따라서 평점은 사용자의 장르별 선호도 벡터와 영화의 장르별 특성 벡터를 서로 곱해서 만들 수 있다.\n",
    "  - $R(1,1) = 4$ (User 1의 Item 1의 평점) == $P$ 행렬의 User 1 벡터 $\\times$ $Q.T$ 행렬의 Item 1 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6.6 예측 평점 계산\n",
    "\n",
    "- 아직 User 1이 평점을 매기지 못한 Item 2에 대해 예측 평점을 수행 ($R(1,2)$)\n",
    "  - $R(1,2)$는 행렬 분해된 $P$ 행렬의 User 1 벡터와 $Q.T$ 행렬의 Item 2 벡터의 내적 결과값인 2.56으로 예측할 수 있다.\n",
    "  \n",
    "<img src=\"images/Ch09/04/img003.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.7 행렬 분해 (Matrix Factorization)\n",
    "\n",
    "- 이처럼 잠재 요인 협업 필터링은 숨겨져 있는 '잠재 요인'을 기반으로 분해된 매트릭스를 이용해 사용자가 아직 평가하지 않은 아이템에 대한 예측 평가를 수행하는 것이다.\n",
    "- 사용자-아이템 평점 행렬과 같이 다차원의 매트릭스를 저차원의 매트릭스로 분해하는 기법을 **행렬 분해(Matrix Factorization)라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 행렬 분해의 이해\n",
    "\n",
    "- 행렬 분해 : 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법  \n",
    "  \n",
    "  \n",
    "- 대표적으로 2가지 종류가 있다.\n",
    "  1. SVD(Singular Vector Decomposition)\n",
    "  2. NMF(Non-Negative Matrix Factorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Factorization (분해)\n",
    "\n",
    "- Factorization은 우리말로 \"인수분해\"를 말한다.\n",
    "- **인수분해**는 일반적으로 하나의 복잡한 다항식을 두 개 이상의 좀 더 단순한 인수(factor)의 곱으로 분해하는 것을 말한다.\n",
    "  - $x^2 + 5x + 6 \\Rightarrow (x+2) \\times (x+3)$\n",
    "- 행렬 분해는 인수분해의 대상이 행렬이 되는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 행렬 분해 요소\n",
    "\n",
    "평점 행렬 $R$\n",
    "  - $M$개의 사용자(User) 행과 $N$개의 아이템(Item) 열을 가진 $M \\times N$ 차원으로 구성  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬 분해를 통해서 다음 2가지의 행렬로 분해된다.\n",
    "\n",
    "**1) 행렬 $P$**\n",
    "  - 사용자-$K$ 차원 잠재 요인 행렬\n",
    "  - $P$는 $M \\times K$ 차원  \n",
    "  \n",
    "  \n",
    "**2) 행렬 $Q.T$**\n",
    "  - $K$ 차원 잠재 요인-아이템 행렬\n",
    "  - $Q.T$는 $K \\times N$ 차원  \n",
    "  \n",
    "  \n",
    "(참고) 행렬 $Q$\n",
    "  - 아이템-잠재 요인 행렬\n",
    "  - $Q.T$는 $Q$의 전치 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Ch09/04/img004.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, $R = P \\cdot Q.T$ 이며 각 기호에 대한 설명은 다음과 같다.\n",
    "\n",
    "- $M$ : 총 사용자 수\n",
    "- $N$ : 총 아이템 수\n",
    "- $K$ : 잠재 요인의 차원 수\n",
    "- $R$ : $M \\times N$ 차원의 사용자-아이템 평점 행렬\n",
    "- $P$ : 사용자와 잠재 요인과의 관계 값을 가지는 $M \\times K$ 차원의 사용자-잠재 요인 행렬\n",
    "- $Q$ : 아이템과 잠재 요인과의 관계 값을 가지는 $N \\times K$ 차원의 아이템-잠재 요인 행렬\n",
    "- $Q.T$ : $Q$ 매트릭스의 행과 열 값을 교환한 전치 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 고차원 희소 행렬 분해\n",
    "\n",
    "- 행렬 내에 NaN 값을 많이 가지는 고차원의 희소 행렬인 $R$ 행렬은 다음 그림과 같이 저차원의 밀집 행렬인 $P$ 행렬과 $Q$ 행렬로 분해될 수 있다.\n",
    "\n",
    "<img src=\"images/Ch09/04/img005.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $r(u,i) = p_u \\cdot q_i^t$ : $R$ 행렬의 $u$행 사용자와 $i$열 아이템 위치에 있는 평점 데이터\n",
    "  - $p_u$ : $P$ 행렬에서 $u$행 사용자의 벡터\n",
    "  - $q_i^t$ : $Q$ 행렬의 $i$행 아이템 벡터의 전치 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3.1 평가된 아이템(영화)에 대한 평점 예측\n",
    "\n",
    "- $r(2,4) = 3$ : $R$ 행렬의 2행 사용자와 5열 아이템의 평점 = 3  \n",
    "$\\Rightarrow$ $r(2,4) = p_2 \\cdot q_4^t$\n",
    "- 따라서 $r(2,4)$의 예측값은 $2.14 \\times 1.36 + 0.08 \\times 0.75 = 2.97$로 계산할 수 있다.\n",
    "\n",
    "<img src=\"images/Ch09/04/img006.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3.2 평가되지 않은 아이템(영화)에 대한 평점 예측\n",
    "\n",
    "- 사용자가 평가하지 않은 아이템(영화)에 대한 평점도 잠재 요인으로 분해된 $P$ 행렬과 $Q$ 행렬을 이용해 예측할 수 있다.  \n",
    "  \n",
    "  \n",
    "- $R$ 행렬의 2행 사용자와 3열 아이템에 해당하는 $r(2,3)$ 은 아직 사용자가 평점을 매기지 않은 미정(NaN) 데이터지만, $r(2,3) = p_2 \\cdot q_3^t$ 로 유추할 수 있다.\n",
    "- 따라서 이 식으로 유추된 $r(2,3)$의 예측값은 $2.14 \\times 1.41 + 0.08 \\times 0.14 = 3.02$이다.\n",
    "\n",
    "<img src=\"images/Ch09/04/img007.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 예측 평점 계산\n",
    "\n",
    "- 사용자-아이템 평점 행렬의 미정 값을 포함한 모든 평점 값은 행렬 분해를 통해 얻어진 $P$ 행렬과 $Q.T$ 행렬의 내적을 통해 예측 평점으로 다시 계산할 수 있다.\n",
    "\n",
    "$$\n",
    "R \\cong \\hat{R} = P \\cdot Q.T\n",
    "$$\n",
    "\n",
    "<img src=\"images/Ch09/04/img008.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 행렬 분해 방법\n",
    "\n",
    "- 그렇다면 $R$ 행렬을 어떻게 $P$와 $Q$ 행렬로 분해할까?\n",
    "- 행렬 분해는 주로 **SVD(Singular Value Decomposition)** 방식을 이용한다.\n",
    "- 하지만 SVD는 `NaN` 값이 없는 행렬에만 적용할 수 있다.\n",
    "- $R$ 행렬에는 아직 평점이 부여되지 않은 많은 $NaN$ 값이 있기 때문에 $P$와 $Q$ 행렬을 일반적인 SVD 방식으로는 분해할 수 없다.\n",
    "- 이러한 경우 다음과 같은 방식을 이용해 SVD를 수행한다.\n",
    "  - **확률적 경사 하강법 (Stochastic Cradient Descent, SGD)**\n",
    "  - **ALS (Alternating Least Squares)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 확률적 경사 하강법을 이용한 행렬 분해\n",
    "\n",
    "- 확률적 경사 하강법(Stochastic Gradient Descent)은 5장 회귀에서 배운 경사 하강법의 한 종류이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 확률적 경사 하강법을 이용한 행렬 분해 방법 요약\n",
    "\n",
    "> $P$와 $Q$ 행렬로 계산된 예측 $R$ 행렬 값이 실제 $R$ 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 $P$와 $Q$를 유추해내는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 확률적 경사 하강법(이하 SGD)을 이용한 행렬 분해의 전반적인 절차\n",
    "\n",
    "1. $P$와 $Q$를 임의의 값을 가진 행렬로 설정\n",
    "2. $P$와 $Q.T$ 값을 곱해 예측 $R$ 행렬을 계산하고, 예측 $R$ 행렬과 실제 $R$ 행렬에 해당하는 오류 값을 계산\n",
    "3. 이 오류 값을 최소화할 수 있도록 $P$와 $Q$ 행렬을 적절한 값으로 각각 업데이트\n",
    "4. 만족할 만한 오류 값을 가질 때까지 2, 3번 작업을 반복하면서 $P$와 $Q$ 값을 업데이트해 근사화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 비용 함수 식\n",
    "\n",
    "- **실제 값과 예측 값의 오류 최소화**와 **L2 규제(Regularization)**를 고려한 비용 함수식\n",
    "\n",
    "$$\n",
    "min \\sum \\left( r(u,i) - p_u q_i^t \\right)^2 + \\lambda \\left( ||q_i||^2 + ||p_u||^2 \\right)\n",
    "$$\n",
    "\n",
    "- 일반적으로 사용자-아이템 평점 행렬의 경우 행렬 분해를 위해서 단순히 예측 오류값의 최소화와 학습 시 과적합을 피하기 위해서 규제를 반영한 비용 함수를 적용한다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 업데이트 식\n",
    "\n",
    "- 위의 비용 함수를 최소화하기 위해서 새롭게 업데이트되는 $p_u'$와 $q_i'$는 다음과 같이 계산할 수 있다.\n",
    "\n",
    "$$\n",
    "p_u' = p_u + \\eta \\left( e(u,i) \\times q_i - \\lambda \\times p_u \\right) \n",
    "$$\n",
    "\n",
    "$$\n",
    "q_i' = q_i + \\eta \\left( e(u,i) \\times p_u - \\lambda \\times q_i \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 기호의 의미\n",
    "\n",
    "- 4.2.3의 비용 함수 식과 4.2.4의 업데이트 식의 기호가 의미하는 바는 다음과 같다.\n",
    "\n",
    "- $p_u$ : $P$ 행렬의 사용자 $u$행 벡터  \n",
    "  \n",
    "  \n",
    "- $q_i^t$ : $Q$ 행렬의 아이템 $i$행의 전치 벡터(transpose vector)  \n",
    "  \n",
    "  \n",
    "- $r(u,i)$ : 실제 $R$ 행렬의 $u$행, $i$열에 위치한 값  \n",
    "  \n",
    "  \n",
    "- $\\hat{r}(u,i)$\n",
    "  - 예측 $\\hat{R}$ 행렬의 $u$행, $i$열에 위치한 값\n",
    "  - $p_u \\cdot q_i^t$로 계산  \n",
    "  \n",
    "  \n",
    "- $e(u,i)$\n",
    "  - $u$행, $i$열에 위치한 실제 행렬 값과 예측 행렬 값의 차이 오류\n",
    "  - $r(u,i) - \\hat{r} (u,i)$로 계산  \n",
    "  \n",
    "  \n",
    "- $\\eta$ : SGD 학습률  \n",
    "  \n",
    "  \n",
    "- $\\lambda$ : L2 규제(Regularization) 계수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6 비용 함수 최소화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6.1 경사 하강법을 이용한 회귀의 비용 함수 최소화\n",
    "\n",
    "- 5장 3절에서 설명한 경사 하강법을 이용한 회귀는 비용 함수를 최소화하는 방향성을 가지고 회귀 계수의 업데이트 값(w1_update, w0_update)을 구하고 이 업데이트 값을 회귀 계수에 반복적으로 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6.2 SGD 기반의 행렬 분해\n",
    "\n",
    "- L2 규제를 반영해 실제 $R$ 행렬 값과 예측 $R$ 행렬 값의 차이를 최소화하는 방향성을 가지고 $P$ 행렬과 $Q$ 행렬에 업데이트 값을 반복적으로 수행하면서 최적화된 예측 R 행렬을 구하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.7 SGD 이용 행렬 분해 수행 예제\n",
    "\n",
    "- 분해하려는 원본 행렬 $R$을 $P$와 $Q$로 분해한 뒤에 다시 $P$와 $Q.T$의 내적으로 예측 행렬을 만드는 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7.1 변수 초기화\n",
    "\n",
    "- 원본 행렬 $R$  \n",
    ": 미정인 널 값(`np.NaN`)을 포함해 생성\n",
    "- 분해 행렬 $P$와 $Q$  \n",
    ": 정규 분포를 가진 랜덤 값으로 초기화\n",
    "- 잠재 요인 차원 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4., nan, nan,  2., nan],\n",
       "       [nan,  5., nan,  3.,  1.],\n",
       "       [nan, nan,  3.,  4.,  4.],\n",
       "       [ 5.,  2.,  1.,  2., nan]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재 요인 차원 K는 3으로 설정\n",
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
    "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
    "              [5, 2, 1, 2, np.NaN ]])\n",
    "\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_items = R.shape\n",
    "K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\n",
      " [[ 0.54144845 -0.2039188  -0.17605725]\n",
      " [-0.35765621  0.28846921 -0.76717957]\n",
      " [ 0.58160392 -0.25373563  0.10634637]\n",
      " [-0.08312346  0.48736931 -0.68671357]]\n",
      "\n",
      "Q :\n",
      " [[-0.1074724  -0.12801812  0.37792315]\n",
      " [-0.36663042 -0.05747607 -0.29261947]\n",
      " [ 0.01407125  0.19427174 -0.36687306]\n",
      " [ 0.38157457  0.30053024  0.16749811]\n",
      " [ 0.30028532 -0.22790929 -0.04096341]]\n"
     ]
    }
   ],
   "source": [
    "# P와 Q 행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력\n",
    "np.random.seed(1)\n",
    "\n",
    "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
    "\n",
    "print('P :\\n', P)\n",
    "print()\n",
    "print('Q :\\n', Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7.2 `get_rmse()` 함수\n",
    "\n",
    "- 실제 $R$ 행렬과 예측 행렬의 오차를 구하는 `get_rmse()` 함수 생성  \n",
    "  \n",
    "  \n",
    "- 실제 $R$ 행렬의 널이 아닌 행렬 값의 위치 인덱스를 추출\n",
    "- 이 인덱스에 있는 실제 $R$ 행렬 값과 분해된 $P$, $Q$ 를 이용해 다시 조합된 예측 행렬 값의 RMSE 값을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    \n",
    "    error = 0\n",
    "    \n",
    "    # 두 개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출해 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    \n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    \n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7.3 SGD 기반 행렬 분해 수행\n",
    "\n",
    "- 먼저 R에서 널 값을 제외한 데이터의 행렬 인덱스를 추출  \n",
    "  \n",
    "  \n",
    "- `steps` : SGD를 반복해서 업데이트할 횟수\n",
    "- `learning_rate` : 학습률\n",
    "- `r_lambda` : L2 Regularization 계수  \n",
    "  \n",
    "  \n",
    "- `steps` 1000번 동안 다음 식을 통해 새로운 $p_u$, $q_i$ 값으로 업데이트\n",
    "  - $p_u' = p_u + \\eta \\left( e(u,i) \\times q_i - \\lambda \\times p_u \\right)$\n",
    "  - $q_i' = q_i + \\eta \\left( e(u,i) \\times p_u - \\lambda \\times q_i \\right)$  \n",
    "  \n",
    "  \n",
    "- 그리고 `get_rmse()` 함수를 통해 50회 반복할 때마다 오류 값을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 4.0),\n",
       " (0, 3, 2.0),\n",
       " (1, 1, 5.0),\n",
       " (1, 3, 3.0),\n",
       " (1, 4, 1.0),\n",
       " (2, 2, 3.0),\n",
       " (2, 3, 4.0),\n",
       " (2, 4, 4.0),\n",
       " (3, 0, 5.0),\n",
       " (3, 1, 2.0),\n",
       " (3, 2, 1.0),\n",
       " (3, 3, 2.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R > 0인 행 위치, 열 위치 값을 non_zeros 리스트에 저장\n",
    "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "non_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  0  rmse :  3.2388050277987723\n",
      "### iteration step :  50  rmse :  0.4876723101369647\n",
      "### iteration step :  100  rmse :  0.15643403848192475\n",
      "### iteration step :  150  rmse :  0.07455141311978038\n",
      "### iteration step :  200  rmse :  0.04325226798579314\n",
      "### iteration step :  250  rmse :  0.029248328780878977\n",
      "### iteration step :  300  rmse :  0.022621116143829396\n",
      "### iteration step :  350  rmse :  0.01949363619652524\n",
      "### iteration step :  400  rmse :  0.018022719092132586\n",
      "### iteration step :  450  rmse :  0.017319685953442663\n",
      "### iteration step :  500  rmse :  0.016973657887570895\n",
      "### iteration step :  550  rmse :  0.016796804595895595\n",
      "### iteration step :  600  rmse :  0.016701322901884613\n",
      "### iteration step :  650  rmse :  0.01664473691247672\n",
      "### iteration step :  700  rmse :  0.016605910068210078\n",
      "### iteration step :  750  rmse :  0.016574200475704973\n",
      "### iteration step :  800  rmse :  0.01654431582921599\n",
      "### iteration step :  850  rmse :  0.016513751774735196\n",
      "### iteration step :  900  rmse :  0.016481465738194947\n",
      "### iteration step :  950  rmse :  0.016447171683479155\n"
     ]
    }
   ],
   "source": [
    "steps = 1000\n",
    "learning_rate = 0.01\n",
    "r_lambda = 0.01\n",
    "\n",
    "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트\n",
    "for step in range(steps):\n",
    "    \n",
    "    for i, j, r in non_zeros:\n",
    "        \n",
    "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "        \n",
    "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "        P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "        Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "        \n",
    "    rmse = get_rmse(R, P, Q, non_zeros)\n",
    "    \n",
    "    if (step % 50) == 0:\n",
    "        print(\"### iteration step : \", step, \" rmse : \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7.4 예측 행렬\n",
    "\n",
    "- 이제 분해된 $P$와 $Q$ 함수를 $P \\cdot Q.T$로 예측 행렬을 만들어서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 행렬:\n",
      " [[3.991 0.897 1.306 2.002 1.663]\n",
      " [6.696 4.978 0.979 2.981 1.003]\n",
      " [6.677 0.391 2.987 3.977 3.986]\n",
      " [4.968 2.005 1.006 2.017 1.14 ]]\n"
     ]
    }
   ],
   "source": [
    "pred_matrix = np.dot(P, Q.T)\n",
    "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 행렬과 비교해 널이 아닌 값은 큰 차이가 나지 않음\n",
    "- 널인 값은 새로운 예측 값으로 채워짐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
