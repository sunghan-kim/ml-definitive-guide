{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9. 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. 파이썬 추천 시스템 패키지 - Surprise\n",
    "\n",
    "p601(620)~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Surprise 패키지 소개\n",
    "\n",
    "- 앞에서 다룬 예제 코드는 최적화나 수행 속도 측면에서 좀 더 보완이 필요하다.\n",
    "- 추천 시스템은 상업적으로 가치가 크기 때문에 별도의 패키지로 제공되면 매우 활용도가 높을 것이다.\n",
    "- 이번에는 파이썬 기반의 추천 시스템 구축을 위한 전용 패키지 중 하나인 Surprise를 소개한다.  \n",
    "(사이킷런은 추천 전용 모듈을 제공하지 않는다.)  \n",
    "  \n",
    "  \n",
    "- Surprise는 파이썬 기반에서 사이킷런과 유사한 API와 프레임워크를 제공한다.\n",
    "- 따라서 추천 시스템의 전반적인 알고리즘을 이해하고 사이킷런 사용 경험이 있으면 쉽게 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 Surprise 패키지 설치\n",
    "\n",
    "```\n",
    "pip install scikit-surprise\n",
    "```\n",
    "\n",
    "```\n",
    "conda install -c conda-forge scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 Surprise 패키지 주요 장점\n",
    "\n",
    "- 다양한 추천 알고리즘(ex. 사용자 또는 아이템 기반 최근접 이웃 협업 필터링, SVD, SVD++, NMF 기반의 잠재 요인 협업 필터링)을 쉽게 적용해 추천 시스템을 구축할 수 있다.\n",
    "- Surprise의 핵심 API는 사이킷런의 핵심 API와 유사한 API명으로 작성됐다.\n",
    "  - `fit()`, `predict()` API로 추천 데이터 학습과 예측\n",
    "  - `train_test_split()`으로 추천 학습 데이터 세트와 예측 데이터 세트 분리\n",
    "  - `cross_validate()`, `GridSearchCV()` 클래스를 통해 추천 시스템을 위한 모델 셀렉션, 평가, 하이퍼 파라미터 튜닝\n",
    "  - 위와 같은 기능들을 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Surprise를 이용한 추천 시스템 구축\n",
    "\n",
    "- [Surprise에 대한 문서](https://surprise.readthedocs.io/en/stable/)\n",
    "- 위 문서 중 간단한 예제를 통해 Surprise 패키지의 개략적인 사용법 확인  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 실습 예제 내용\n",
    "\n",
    "- 추천 데이터를 학습용과 테스트용 데이터 세트로 분리\n",
    "- SVD 행렬 분해를 통한 잠재 요인 협업 필터링 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 Surprise 관련 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 데이터셋 로딩\n",
    "\n",
    "- 추천을 위한 데이터셋 로딩\n",
    "- Surprise에서 데이터 로딩은 `Dataset` 클래스를 이용해서만 가능하다.\n",
    "- Surprise는 Movie Lens 데이터 세트의 사용자-영화 평점 데이터 포맷과 같이 `userId`(사용자ID), `movieId`(영화ID), `rating`(평점)과 같은 주요 데이터가 로우(Row) 레벨 형태로 되어 있는 포맷의 데이터만 처리한다.\n",
    "\n",
    "<img src=\"./images/Ch09/08/img001.jpg\" />\n",
    "\n",
    "- Surprise는 무비렌즈(MovieLens) 사이트에서 제공하는 과거 버전의 데이터 세트를 가져오는 API를 제공한다.\n",
    "- Surprise `Dataset` 클래스의 `load_builtin()`\n",
    "  - 무비렌즈 사이트에서 제공하는 과거 버전 데이터 세트인 'ml-100k'(10만 개 평점 데이터) 또는 'ml-1m'(100만 개 평점 데이터) 데이터를 아카이브 사이트로부터 내려받아 로컬 디렉토리에 저장한 뒤 데이터를 로딩한다.\n",
    "- 이렇게 로딩한 데이터 세트를 Surpsrise 패키지의 `train_test_split()` API를 이용해 학습 데이터 세트와 테스트 데이터 세트로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\krx-mktinfo/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# 수행 시마다 동일하게 데이터를 분할하기 위해 random_state 값 부여\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 내려받기가 완료되면 데이터가 저장된 디렉터리가 다음과 같이 표시된다.\n",
    "\n",
    "```\n",
    "C:\\Users\\krx-mktinfo/.surprise_data/ml-100k\n",
    "```\n",
    "\n",
    "- 한 번 내려받아 로컬 디렉터리에 데이터가 저장된 후에는 `Dataset.load_builtin('ml-100k')`을 호출하면 무비렌즈 사이트에 접속하지 않고 저장된 데이터 세트를 로딩할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Surprise에서 사용하는 'ml-100k' 데이터 세트는 앞 예제에서 지금까지 사용한 `movies.csv`, `ratings.csv` 파일과는 차이가 있다.\n",
    "  - 무비렌즈 사이트에서 직접 내려받은 `movies.csv`, `ratings.csv`\n",
    "    - 최근 영화에 대한 평점 정보를 가지고 있음\n",
    "    - 컬럼 분리 문자가 콤마(`,`)인 csv 파일\n",
    "  - Surprise가 내려받은 ml-100k, ml-1m\n",
    "    - 과거 버전의 데이터 세트\n",
    "    - 분리 문자가 탭(`\\t`) 문자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 Surprise에 사용자-아이템 평점 데이터 적용 시 주의사항\n",
    "\n",
    "- 무비렌즈 사이트에 내려받은 데이터 파일과 동일하게 **로우 레벨의 사용자-아이템 평점 데이터를 그대로 적용**해야 한다.\n",
    "  - 앞의 예제에서 로우 레벨의 사용자-아이템 평점 데이터를 아이템 아이디를 컬럼명으로 변환한 형태의 사용자-아이템 평점 행렬 데이터로 변환했다.\n",
    "  - Surprise는 자체적으로 로우 레벨의 데이터를 컬럼 레벨의 데이터로 변경하므로 원본인 로우 레벨의 사용자-아이템 평점 데이터를 데이터 세트로 적용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.5 SVD 이용 잠재 요인 협업 필터링 수행\n",
    "\n",
    "- 적용하는 데이터 세트 : `train_test_split()`으로 분리된 학습 데이터 세트\n",
    "\n",
    "```python\n",
    "algo = SVD()\n",
    "```\n",
    "\n",
    "- 알고리즘 객체 생성  \n",
    "  \n",
    "  \n",
    "- 이 알고리즘 객체에 `fit(학습 데이터 세트)`를 수행해 학습 데이터 세트 기반으로 추천 알고리즘을 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x881b2e8da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.6 학습된 추천 알고리즘 기반 추천 수행\n",
    "\n",
    "- 학습된 추천 알고리즘을 기반으로 테스트 데이터 세트에 대해 추천을 수행\n",
    "- Surprise에서 추천을 예측하는 메서드는 2가지 메서드가 있다.\n",
    "  - `test()`\n",
    "    - 사용자-아이템 평점 데이터 세트 전체에 대해서 추천을 예측하는 메서드\n",
    "    - 즉, 입력된 데이터 세트에 대해 추천 데이터 세트를 만들어 준다.\n",
    "  - `predict()`\n",
    "    - 개별 사용자와 영화에 대한 추천 평점을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.6.1 `test()` 메서드를 통한 추천 수행\n",
    "\n",
    "- 테스트 데이터 세트 전체에 대해 추천 영화 평점 데이터를 새엉한 뒤 최초 5개만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type : <class 'list'>  size: 25000\n",
      "prediction 결과의 최초 5개 추출\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='120', iid='282', r_ui=4.0, est=3.553104791407395, details={'was_impossible': False}),\n",
       " Prediction(uid='882', iid='291', r_ui=4.0, est=3.639212634644528, details={'was_impossible': False}),\n",
       " Prediction(uid='535', iid='507', r_ui=5.0, est=4.03495200520685, details={'was_impossible': False}),\n",
       " Prediction(uid='697', iid='244', r_ui=5.0, est=3.655508248630315, details={'was_impossible': False}),\n",
       " Prediction(uid='751', iid='385', r_ui=4.0, est=3.024294678761952, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(testset)\n",
    "print('prediction type :', type(predictions), ' size:', len(predictions))\n",
    "print('prediction 결과의 최초 5개 추출')\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVD 알고리즘 객체의 `test(데이터 세트)` 메서드의 호출 결과는 **파이썬 리스트**이다.\n",
    "- 크기는 입력 인자 데이터 세트의 크기와 같은 25,000개이다.\n",
    "- 호출 결과로 반환된 리스트 객체는 25,000개의 `Prediction` 객체를 내부에 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Prediction` 객체**\n",
    "\n",
    "- Surprise 패키지에서 제공하는 데이터 타입  \n",
    "  \n",
    "  \n",
    "- 다음과 같은 데이터를 튜플 형태로 가지고 있다.\n",
    "  - 개별 사용자 아이디(`uid`)\n",
    "  - 영화(또는 아이템) 아이디(`iid`)\n",
    "  - 실제 평점(`r_ui`)\n",
    "  - 위 3가지 정보에 기반에 Surprise의 추천 예측 평점(`est`)  \n",
    "  \n",
    "  \n",
    "- `details` 속성\n",
    "  - 내부 처리 시 추천 예측을 할 수 없는 경우에 로그용으로 데이터를 남기는 데 사용된다.\n",
    "  - `was_impossible=True` : 예측값을 생성할 수 없는 데이터라는 의미  \n",
    "  (여기서는 모두 `False`로 되어 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 리스트 객체 내에 내포된 `Prediction` 객체의 `uid`, `iid`, `r_ui`, `est` 등의 속성에 접근하려면 `객체명.uid`와 같은 형식으로 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3개의 `Prediction` 객체에서 `uid`, `iid`, `est` 속성을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '282', 3.553104791407395),\n",
       " ('882', '291', 3.639212634644528),\n",
       " ('535', '507', 4.03495200520685)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (pred.uid, pred.iid, pred.est) for pred in predictions[:3] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.6.2 `predict()` 메서드를 통한 추천 수행\n",
    "\n",
    "- `predict()`는 개별 사용자의 아이템에 대한 추천 평점을 예측해준다.\n",
    "- 인자\n",
    "  - 개별 사용자 아이디\n",
    "  - 아이템 아이디\n",
    "- 위의 인자들을 입력하면 추천 예측 평점을 포함한 정보를 반환한다.  \n",
    "(기존 평점 정보(`r_ui`)는 선택 사항이며, 사용자 아이디, 아이템 아이디는 문자열로 입력해야 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = None   est = 4.45   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# 사용자 아이디, 아이템 아이디는 문자열로 입력해야 함\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `predict()`는 개별 사용자와 아이템 정보를 입력하면 추천 예측 평점을 `est`로 반환한다.  \n",
    "  \n",
    "  \n",
    "- `test()` 메서드는 입력 데이터 세트의 모든 사용자와 아이템 아이디에 대해서 `predict()`를 반복적으로 수행한 결과라고 생각하면 이해하기 쉽다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.7 평가\n",
    "\n",
    "- 테스트 데이터 세트를 이용해 추천 예측 평점과 실제 평점과의 차이를 평가\n",
    "- Surprise의 `accuracy` 모듈은 RMSE, MSE 등의 방법으로 추천 시스템의 성능 평가 정보를 제공한다.\n",
    "- `accuracy` 모듈의 `rmse()`를 이용해 RMSE 평가 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.949150888144858"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Surprise 주요 모듈 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 `Dataset`\n",
    "\n",
    "- Surprise는 `user_id`(사용자 아이디), `item_id`(아이템 아이디), `rating`(평점) 데이터가 로우 레벨로 된 데이터 세트에만 적용할 수 있다.\n",
    "- 데이터의 첫 번째 컬럼을 사용자 아이디, 두 번째 컬럼을 아이템 아이디, 세 번째 컬럼을 평점으로 가정해 데이터를 로딩\n",
    "- 네 번째 컬럼부터는 아예 로딩을 수행하지 않는다.\n",
    "- ex) `user_id`, `item_id`, `rating`, `time_stamp` 필드로 구분된 데이터\n",
    "  - 앞 3개 필드만 로딩하고 이후 `time_stamp` 필드는 로딩에서 제외됨  \n",
    "  \n",
    "- 무비렌즈 아카이브 서버에서 자동으로 내려받는 데이터 파일뿐만 아니라 일반 데이터 파일이나 판다스 DataFrame에서도 로딩할 수 있다.\n",
    "- 단, 데이터 세트의 컬럼 순서가 사용자 아이디, 아이템 아이디, 평점 순으로 반드시 돼 있어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| API 명                                      | 내용                                                         |\n",
    "| ------------------------------------------- | ------------------------------------------------------------ |\n",
    "| `Dataset.load_builtin(name='ml-100k')`      | - 무비렌즈 아카이브 FTP 서버에서 무비렌즈 데이터를 내려받음<br />- `ml_100k`, `ml_1M`를 내려받을 수 있다.<br />- 일단 내려받은 데이터는 `.surprise_data` 디렉터리 밑에 저장됨<br />- 해당 디렉터리에 데이터가 있으면 FTP에서 내려받지 않고 해당 데이터를 이용<br />- 입력 파라미터인 `name`으로 대상 데이터가 `ml-100k`인지 `ml-1m`인지를 입력한다.<br />- `name` 파라미터의 디폴트 값은 `ml-100k`이다. |\n",
    "| `Dataset.load_from_file(file_path, reader)` | - OS 파일에서 데이터를 로딩할 때 사용<br />- 콤마, 탭 등으로 컬럼이 분리된 포맷의 OS 파일에서 데이터를 로딩<br />- 입력 파라미터로 OS 파일명, Reader로 파일의 포맷을 지정 |\n",
    "| `Dataset.load_from_df(df, reader)`          | - 판다스의 DataFrame에서 데이터를 로딩<br />- 파라미터로 DataFrame을 입력받음<br />- DataFrame 역시 받느시 3개의 컬럼인 사용자 아이디, 아이템 아이디, 평점 순으로 컬럼 순서가 정해져 있어야 한다.<br />- 입력 파라미터로 DataFrame 객체, Reader로 파일 포맷을 지정 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.1.1 OS 파일 데이터를 Surprise 데이터 세트로 로딩\n",
    "\n",
    "- `Dataset.load_from_file` API를 이용해 지정된 디렉터리에 있는 사용자-아이템 평점 데이터를 로딩\n",
    "- 사용할 데이터는 이전 절에서 사용한 `ratings.csv`와 `movies.csv`이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 데이터 세트 헤더 제거**\n",
    "\n",
    "- Surprise에 OS 파일을 로딩할 때 주의할 점은로딩되는 데이터 파일에 컬럼명을 가지는 **헤더 문자열이 있어서는 안된다**는 것이다.\n",
    "  \n",
    "<img src=\"./images/Ch09/08/img002.jpg\" />\n",
    "\n",
    "- 여기서 사용할 `ratings.csv` 파일은 맨 처음 위치에 컬럼명을 헤더로 가지고 있다.\n",
    "- 판다스 DataFrame의 `to_csv()` 함수를 이용해 이 컬럼 헤더를 삭제하고 새로운 파일인 `ratings_noh.csv`로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('./data/Grouplens/ml-latest-small/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_noh.csv 파일로 업로드 시 인덱스와 헤더를 모두 제거한 새로운 파일 생성\n",
    "ratings.to_csv('./data/Grouplens/ml-latest-small/ratings_noh.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 새롭게 생성된 `ratings_noh.csv` 파일은 `ratings.csv` 파일에서 헤더가 삭제된 파일이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) `Reader` 클래스 이용 포맷 정의**\n",
    "\n",
    "- 이제 `ratings_noh.csv`를 `Dataset` 모듈의 `load_from_file()`을 이용해 `Dataset`으로 로드한다.\n",
    "- 먼저 `Dataset.load_from_file()`을 적용하기 전에 `Reader` 클래스를 이용해 데이터 파일의 파생 포맷을 정의해야 한다.\n",
    "- `Reader` 클래스는 로딩될 `ratings_noh.csv` 파일의 파싱 정보를 알려주기 위해 사용된다.\n",
    "- 지금 로딩하려는 `ratings_noh.csv`는 컬럼 헤더가 없고, 4개의 컬럼이 콤마(`,`)로만 분리되어 있다.\n",
    "- 이 4개의 컬럼이 사용자 아이디, 아이템 아이디, 평점, 타임스탬프임을 로딩할 때 알려줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Reader` 클래스의 생성자에 각 필드의 컬럼명과 컬럼 분리문자, 그리고 최소~최대 평점을 입력해 객체를 생성\n",
    "- `load_from_file()`로 생성된 `Reader` 객체를 참조해 데이터 파일을 파싱하면서 로딩한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Reader` 객체 생성 시에 `line_format` 인자로 `user`, `item`, `rating`, `timestamp`의 4개의 컬럼으로 데이터가 구성돼 있음을 명시\n",
    "- 각 컬럼의 분리 문자는 콤마\n",
    "- 평점의 단위는 0.5\n",
    "- 최대 평점은 5점으로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Reader` 설정이 완료되면 `Dataset.load_from_file()`은 이를 기반으로 데이터를 파싱하면서 `Dataset`를 로딩한다.\n",
    "- 로딩 시 `ratings_noh.csv` 파일에서 앞의 3개 컬럼만 로딩되고 `timestamp` 컬럼은 제외된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp',\n",
    "                sep=',',\n",
    "                rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_file('./data/Grouplens/ml-latest-small/ratings_noh.csv', reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Surprise 데이터 세트는 기본적으로 무비렌즈 데이터 형식을 따르므로 무비렌즈 데이터 형식이 아닌 다른 OS 파일의 경우 `Reader` 클래스를 먼저 설정해야 한다.  \n",
    "  \n",
    "  \n",
    "- `Reader` 클래스의 주요 생성 파라미터\n",
    "  - `line_format(string)`\n",
    "    - 컬럼을 순서대로 나열\n",
    "    - 입력된 문자열을 공백으로 분리해 컬럼으로 인식\n",
    "  - `sep(char)`\n",
    "    - 컬럼을 분리하는 분리자\n",
    "    - 디폴트 : `\\t`\n",
    "    - 판다스 DataFrame에서 입력받을 경우에는 기재할 필요가 없다.\n",
    "  - `rating_scale(tuple, optional)`\n",
    "    - 평점 값의 최소 ~ 최대 평점을 설정\n",
    "    - 디폴트 : `(1,5)`\n",
    "    - `ratings.csv` 파일의 경우는 최소 평점이 0.5, 최대 평점이 5이므로 `(0.5, 5)`로 설정했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) SVD 행렬 분해 기법 이용 추천 예측**\n",
    "\n",
    "- 잠재 요인 크기 K 값을 나타내는 파라미터인 `n_factors`를 50으로 설정해 데이터를 학습\n",
    "- 그런 다음 테스트 데이터 세트를 적용해 예측 평점을 구한다.\n",
    "- 그리고 예측 평점과 실제 평점 데이터를 RMSE로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# 수행 시마다 동일한 결과를 도출하기 위해 random_state 설정\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "\n",
    "# 학습 데이터 세트로 학습하고 나서 테스트 데이터 세트로 평점 예측 후 RMSE 평가\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.1.2 판다스 DataFrame에서 Surprise 데이터 세트로 로딩\n",
    "\n",
    "- `Dataset.load_from_df()`를 이용하면 판다스의 DataFrame에서도 Surprise 데이터 세트를 로딩할 수 있다.\n",
    "- 주의할 점\n",
    "  - DataFrame 역시 사용자 아이디, 아이템 아이디, 평점 컬럼 순서를 지켜야 한다.  \n",
    "  \n",
    "  \n",
    "- `ratings.csv` 파일을 DataFrame으로 로딩한 `ratings`에서 Surprise 데이터 세트로 로딩하려면 다음과 같이 파타미터를 입력하면 된다.\n",
    "\n",
    "```python\n",
    "Dataset.load_from_df(ratings[['userId', 'movieId', 'rating]], reader)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이를 이용한 SVD 추천 예측을 코드로 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "ratings = pd.read_csv('./data/Grouplens/ml-latest-small/ratings.csv')\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# ratings DataFrame에서 컬럼은 사용자 아이디, 아이템 아이디, 평점 순서를 지켜야 한다.\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Surprise 추천 알고리즘 클래스\n",
    "\n",
    "- Surprise에서 추천 예측을 위해 자주 사용되는 추천 알고리즘 클래스는 다음과 같다.\n",
    "\n",
    "| 클래스명       | 설명                                                       |\n",
    "| -------------- | ---------------------------------------------------------- |\n",
    "| `SVD`          | 행렬 분해를 통한 잠재 요인 협업 필터링을 위한 SVD 알고리즘 |\n",
    "| `KNNBasic`     | 최근접 이웃 협업 필터링을 위한 KNN 알고리즘                |\n",
    "| `BaselineOnly` | 사용자 Bias와 아이템 Bias를 감안한 SGD 베이스라인 알고리즘 |\n",
    "\n",
    "- 이 밖에도 `SVD++`, `NMF` 등 다양한 유형의 알고리즘을 수행할 수 있다.\n",
    "- [지원 알고리즘 참조 문서](http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1 Surprise SVD 비용 함수\n",
    "\n",
    "- Surprise SVD의 비용 함수는 사용자 베이스라인(Baseline) 편향성을 감안한 평점 예측에 Regularization을 적용한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**사용자 예측 Rating**\n",
    "\n",
    "- $r$^$ui = \\mu + bu + bi + qTipu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization을 적용한 비용 함수**\n",
    "\n",
    "- $\\sum ( rui - r$^$ui )2 + \\lambda (b2i + b2u + ||qi||2 + ||pu||2) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2 SVD 클래스 입력 파라미터\n",
    "\n",
    "- 주로 `n_factors`와 `n_epochs`의 값을 변경해 튜닝할 수 있으나 튜닝 효과는 크지 않다.\n",
    "- `biased`의 경우는 큰 이슈가 없는 한 디폴트인 `True`로 설정을 유지하는 것이 좋다.\n",
    "\n",
    "| 파라미터명     | 내용                                                         |\n",
    "| -------------- | ------------------------------------------------------------ |\n",
    "| `n_factors`    | - 잠재 요인 K의 개수<br />- 디폴트 : 100<br />- 커질수록 정확도가 높아질 수 있으나 과적합 문제가 발생할 수 있다. |\n",
    "| `n_epochs`     | - SGD(Stochastic Gradient Descent) 수행 시 반복 횟수<br />- 디폴트 : 20 |\n",
    "| `based` (bool) | - 베이스라인 사용자 편향 적용 여부<br />- 디폴트 : `True`    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3 추천 알고리즘 예측 성능 벤치마크\n",
    "\n",
    "- 추천 알고리즘의 예측 성능 벤치마크 결과는 [http://surpriselib.com/](http://surpriselib.com/)에서 확인 할 수 있다.\n",
    "- 벤치마크는 Core i5 87th gen (2.5 GHz), 8G RAM 상에서 100k 데이터 세트로 테스트한 결과이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 알고리즘 유형                                                |  RMSE |   MAE | Time    |\n",
    "| :----------------------------------------------------------- | ----: | ----: | :------ |\n",
    "| [SVD](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD) | 0.934 | 0.737 | 0:00:11 |\n",
    "| [SVD++](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp) |  0.92 | 0.722 | 0:09:03 |\n",
    "| [NMF](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF) | 0.963 | 0.758 | 0:00:15 |\n",
    "| [Slope One](http://surprise.readthedocs.io/en/stable/slope_one.html#surprise.prediction_algorithms.slope_one.SlopeOne) | 0.946 | 0.743 | 0:00:08 |\n",
    "| [k-NN](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic) |  0.98 | 0.774 | 0:00:10 |\n",
    "| [Centered k-NN](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans) | 0.951 | 0.749 | 0:00:10 |\n",
    "| [k-NN Baseline](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline) | 0.931 | 0.733 | 0:00:12 |\n",
    "| [Co-Clustering](http://surprise.readthedocs.io/en/stable/co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering) | 0.963 | 0.753 | 0:00:03 |\n",
    "| [Baseline](http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly) | 0.944 | 0.748 | 0:00:01 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVD++ 알고리즘의 RMSE, MAE 성적이 가장 좋지만, 상대적으로 시간이 너무 오래 걸려 데이터가 조금만 더 커져도 사용하기가 어려울 것으로 보인다.\n",
    "- SVD++를 제외하면 SVD와 k-NN Baseline이 가장 성능 평가 수치가 좋다.\n",
    "- k-NN 자체는 성능이 상대적으로 뒤지지만, Baseline을 결합한 경우 성능 평가 수치가 대폭 향상됐다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline**\n",
    "\n",
    "- 각 개인이 평점을 부여하는 성향을 반영해 평점을 계산하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 베이스라인 평점\n",
    "\n",
    "- 개인의 성향을 반영해 아이템 평가에 편향성(bias) 요소를 반영하여 평점을 부과하는 것을 **베이스라인 평점(Baseline Rating)**이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1 베이스라인 평점 계산 공식\n",
    "\n",
    "> 전체 평균 평점 + 사용자 편향 점수 + 아이템 편향 점수\n",
    "\n",
    "- 전체 평균 평점 = 모든 사용자의 아이템에 대한 평점을 평균한 값\n",
    "- 사용자 편향 점수 = 사용자별 아이템 평점 평균 값 - 전체 평균 평점\n",
    "- 아이템 편향 점수 = 아이템별 평점 평균 값 - 전체 평균 평점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2 베이스라인 평점을 고려한 영화 평점\n",
    "\n",
    "- 모든 사용자의 평균적인 영화 평점 = 3.5 (전체 평균 평점 : 3.5)\n",
    "- '어벤져스 3편'을 모든 사용자가 평균적으로 평점 4.2로 평가함\n",
    "- 영화 평가를 깐깐하게 하는 사용자 A가 '어벤져스 3편'을 어떻게 평가할 거신지 예상해보자.\n",
    "\n",
    "<img src=\"./images/Ch09/08/img003.jpg\" />\n",
    "\n",
    "- 전체 평균 평점 : 3.5\n",
    "- 사용자 편향 점수 : 3.0(사용자 A의 평균 영화 평점) - 3.5(전체 평균 평점) = -0.5\n",
    "- 아이템 편향 점수 : 4.2(영화에 대한 모든 사용자의 평균 평점) - 3.5(전체 평균 평점) = 0.7  \n",
    "  \n",
    "  \n",
    "- 따라서 사용자 A의 '어벤져스 3편'의 베이스라인 평점은 3.5 - 0.5 + 0.7 = 3.7 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 교차 검증과 하이퍼 파라미터 튜닝\n",
    "\n",
    "- Surprise는 교차 검증과 하이퍼 파라미터 튜닝을 위해 사이킷런과 유사한 `cross_validate()`와 `GridSearchCV` 클래스를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.1 `cross_validate()`\n",
    "\n",
    "- 해당 함수는 `surprise.model_selection` 모듈 내에 존재\n",
    "- 폴드된 데이터 세트의 개수와 성능 측정 방법을 명시해 교차 검증을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 예제에서 `cross_validate()`를 이용해 `ratings.csv`를 DataFrame으로 로딩한 데이터를 5개의 학습/검증 폴드 데이터 세트로 분리해 교차 검증을 수행하고 RMSE, MAE로 성능 평가를 진행한다.  \n",
    "  \n",
    "  \n",
    "- `cross_validate()`의 인자\n",
    "  - 알고리즘 객체\n",
    "  - 데이터\n",
    "  - 성능 평가 방법(`measures`)\n",
    "  - 폴드 데이터 세트 개수(`cv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8745  0.8666  0.8679  0.8750  0.8775  0.8723  0.0043  \n",
      "MAE (testset)     0.6720  0.6659  0.6666  0.6705  0.6743  0.6698  0.0032  \n",
      "Fit time          5.68    5.33    5.70    5.38    5.59    5.54    0.15    \n",
      "Test time         0.18    0.29    0.18    0.19    0.25    0.22    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87447983, 0.86662765, 0.86794315, 0.87498858, 0.87753643]),\n",
       " 'test_mae': array([0.67196042, 0.66593896, 0.66658246, 0.67047236, 0.67425473]),\n",
       " 'fit_time': (5.6817333698272705,\n",
       "  5.3295814990997314,\n",
       "  5.702349662780762,\n",
       "  5.377593517303467,\n",
       "  5.590756416320801),\n",
       " 'test_time': (0.18144583702087402,\n",
       "  0.2934889793395996,\n",
       "  0.18400907516479492,\n",
       "  0.19032073020935059,\n",
       "  0.25095129013061523)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# 판다스 DataFrame에서 Surprise 데이터 세트로 데이터 로딩\n",
    "ratings = pd.read_csv('./data/Grouplens/ml-latest-small/ratings.csv') # reading data in pandas df\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "algo = SVD(random_state=0)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cross_validate()`는 위의 출력 결과와 같이 폴드별 성능 평가 수치와 전체 폴드의 평균 성능 평가 수치를 함께 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6.2 `GridSearchCV`\n",
    "\n",
    "- Surprise의 `GridSearchCV`도 사이킷런의 `GridSearchCV`와 유사하게 교차 검증을 통한 하이퍼 파라미터 최적화를 수행한다.\n",
    "- 하이퍼 파라미터 최적화는 알고리즘 유형에 따라 다를 수 있다.\n",
    "- SVD의 경우 주로 다음 2가지의 파라미터를 튜닝한다.\n",
    "  - `n_epochs` : 점진적 하강 방식(Stochastic Gradient Descent)의 반복 횟수를 지정\n",
    "  - `n_factors` : SVD의 잠재 요인 K의 크기를 지정  \n",
    "  \n",
    "  \n",
    "- 다음과 같이 하이퍼 파라미터를 변경하면서 CV가 3일 때의 최적 하이퍼 파라미터를 도출한다.\n",
    "\n",
    "```python\n",
    "'n_epochs': [20, 40, 60], 'n_factors': [50, 100, 200]\n",
    "```\n",
    "\n",
    "- 데이터는 앞 예제에서 사용한 `ratings.csv`를 DataFrame으로 로딩한 데이터를 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877674669562989\n",
      "{'n_epochs': 20, 'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# 최적화할 파라미터를 딕셔너리 형태로 지정\n",
    "param_grid = {'n_epochs': [20, 40, 60], 'n_factors': [50, 100, 200]}\n",
    "\n",
    "# CV를 3개 폴드 세트로 지정, 성능 평가는 rmse, mae로 수행하도록 GridSearchCV 구성\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# 최고 RMSE Evaluation 점수와 그때의 하이퍼 파라미터\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n_epochs`가 20, `n_factors`가 50일 때 3개 폴드의 검증 데이터 세트에서 최적 RMSE가 0.877로 도출됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Surprise를 이용한 개인화 영화 추천 시스템 구축\n",
    "\n",
    "- Surprise를 이용해 잠재 요인 협업 필터링 기반의 개인화된 영화 추천을 구현\n",
    "- Surprise 패키지는 간결하지만 기능을 조금 보강할 필요가 있다.\n",
    "- Surprise 패키지로 학습된 추천 알고리즘을 기반으로 특정 사용자가 아직 평점을 매기지 않은(관람하지 않은) 영화 중에서 개인 취향에 가장 적절한 영화를 추천해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.1 훈련 데이터 세트 생성 : `DatasetAutoFolds` 클래스\n",
    "\n",
    "- 이번 예제에서는 `ratings.csv` 데이터를 학습 데이터와 테스트 데이터로 분리하지 않고 전체를 학습 데이터로 사용한다.  \n",
    "  \n",
    "  \n",
    "- Surprise는 데이터 세트를 `train_test_split()`을 이용해 내부에서 사용하는 `TrainSet` 클래스 객체로 변환하지 않으면 `fit()`을 통해 학습할 수가 없다.\n",
    "- 따라서 데이터 세트를 그대로 `fit()`에 적용한 다음 코드는 오류를 일으킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR : 'DatasetAutoFolds' object has no attribute 'global_mean'\n"
     ]
    }
   ],
   "source": [
    "# 다음 코드는 train_test_split()으로 분리되지 않는 데이터 세트에 fit()을 호출해 오류가 발생한다.\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "try:\n",
    "    algo.fit(data)\n",
    "except AttributeError as e:\n",
    "    print('ERROR :', e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 세트 전체를 학습 데이터로 사용하려면 `DatasetAutoFolds` 클래스를 이용하면 된다.\n",
    "- `DatasetAutoFolds` 객체를 생성한 뒤에 `build_full_trainset()` 메서드를 호출하면 전체 데이터를 학습 데이터 세트로 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp',\n",
    "                sep=',',\n",
    "                rating_scale=(0.5, 5))\n",
    "\n",
    "# DatasetAutoFolds 클래스를 ratings_noh.csv 파일 기반으로 생성\n",
    "data_folds = DatasetAutoFolds(ratings_file='./data/Grouplens/ml-latest-small/ratings_noh.csv',\n",
    "                              reader=reader)\n",
    "\n",
    "# 전체 데이터를 학습 데이터로 생성\n",
    "trainset = data_folds.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.2 SVD 이용 학습 수행\n",
    "\n",
    "- 생성된 학습 데이터를 기반으로 학습 수행\n",
    "- 그리고 이후에 특정 사용자에 영화를 추천하기 위해 아직 보지 않은 영화 목록을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x881dd15e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_epochs=20, n_factors=50, random_state=0)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.3 특정 사용자의 예측 평점 확인\n",
    "\n",
    "- 특정 사용자 : `userId=9`인 사용자로 지정\n",
    "- 간단하게 Surprise 패키지의 API를 이용해 예제를 수행하기 위해 `userId=9`인 사용자가 아직 평점을 매기지 않은 영화를 `movieId=42`로 선정한 뒤 예측 평점을 계산\n",
    "- 영화 상세 정보는 `movies.csv` 파일에 있으므로 해당 파일을 DataFrame으로 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 아이디 9는 영화 아이디 42의 평점 없음\n",
      "\n",
      "     movieId                   title              genres\n",
      "38       42  Dead Presidents (1995)  Action|Crime|Drama\n"
     ]
    }
   ],
   "source": [
    "# 영화에 대한 상세 속성 정보 DataFrame 로딩\n",
    "movies = pd.read_csv('./data/Grouplens/ml-latest-small/movies.csv')\n",
    "\n",
    "# userId=9의 movieId 데이터를 추출해 movieId=42 데이터가 있는 지 확인\n",
    "movieIds = ratings[ratings['userId'] == 9]['movieId']\n",
    "\n",
    "if movieIds[movieIds == 42].count() == 0:\n",
    "    print('사용자 아이디 9는 영화 아이디 42의 평점 없음')\n",
    "    \n",
    "print('\\n', movies[movies['movieId'] == 42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 `movieId=42`인 영화에 대해서 `userId=9` 사용자의 추천 예상 평점은 `predict()` 메서드를 이용하면 알 수 있다.\n",
    "- 학습된 `SVD` 객체에서 `predict()` 메서드 내에 `userId`와 `movieId` 값을 입력해주면 된다.  \n",
    "(단, 이 값은 모두 문자열 값이어야 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 9          item: 42         r_ui = None   est = 3.13   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(9)\n",
    "iid = str(42)\n",
    "\n",
    "pred = algo.predict(uid, iid, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추천 예측 평점(`est`) = 3.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7.4 사용자가 평점을 매기지 않은 전체 영화 추출 및 영화 추천\n",
    "\n",
    "- 사용자가 평점을 매기지 않은 전체 영화를 추출\n",
    "- 그런 다음 예측 평점 순으로 영화를 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 먼저 추천 대상이 되는 영화 추출\n",
    "- Surprise 내부의 데이터 객체에 대한 엑세스 제약 등으로 인해 앞 절에서 사용한 `get_unseen_movies()`는 사용하지 않음\n",
    "- 새롭게 `get_unseen_surprise()` 함수를 만들고 이를 이용해 아이디 9인 사용자가 아직 평점을 매기지 않은 영화 정보를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unseen_surprise(ratings, movies, userId):\n",
    "    \n",
    "    # 입력값으로 들어온 userId에 해당하는 사용자가 평점을 매긴 모든 영화를 리스트로 생성\n",
    "    seen_movies = ratings[ratings['userId'] == userId]['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화의 movieId를 리스트로 생성\n",
    "    total_movies = movies['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화의 movieId 중 이미 평점을 매긴 영화의 movieId를 제외한 후 리스트 생성\n",
    "    unseen_movies = [movie for movie in total_movies if movie not in seen_movies]\n",
    "    \n",
    "    print('평점 매긴 영화 수 :', len(seen_movies), ', 추천 대상 영화 수 :', len(unseen_movies),\n",
    "          ' 전체 영화 수 :', len(total_movies))\n",
    "    \n",
    "    return unseen_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화 수 : 46 , 추천 대상 영화 수 : 9696  전체 영화 수 : 9742\n"
     ]
    }
   ],
   "source": [
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용자 아이디 9번은 전체 9742개의 영화 중에서 46개만 평점을 매겼다.\n",
    "- 따라서 추천 대상 영화는 9696개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 중 앞에서 학습된 추천 알고리즘 클래스인 `SVD`를 이용해 높은 예측 평점을 가진 순으로 영화를 추천한다.\n",
    "- 이를 위해 `recomm_movie_by_surprise()` 함수를 새롭게 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`recomm_movie_by_surprise()` 함수**\n",
    "\n",
    "-  파라미터\n",
    "  - 학습이 완료된 추천 알고리즘 객체\n",
    "  - 추천 대상 사용자 아이디\n",
    "  - 추천 대상 영화의 리스트 객체\n",
    "  - 추천 상위 N개 개수  \n",
    "  \n",
    "  \n",
    "- 해당 함수는 추천 대상 영화 모두를 대상으로 추천 알고리즘 객체의 `predict()` 메서드를 호출함\n",
    "- 그리고 그 결과인 `Prediction` 객체를 리스트 객체로 저장\n",
    "- 저장된 리스트 내부의 `Prediction` 객체를 예측 평점이 높은 순으로 다시 정렬\n",
    "- TOP-N개의 `Prediction` 객체에서 영화 아이디, 영화 제목, 예측 평점 정보를 추출해 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomm_movie_by_surprise(algo, userId, unseen_movies, top_n=10):\n",
    "    \n",
    "    # 알고리즘 객체의 predict() 메서드를 평점이 없는 영화에 반복 수행한 후 결과를 list 객체로 저장\n",
    "    predictions = [algo.predict(str(userId), str(movieId)) for movieId in unseen_movies]\n",
    "    \n",
    "    # predictions list 객체는 surprise의 Predictions 객체를 원소로 가지고 있다.\n",
    "    # 이를 est 값으로 정렬하기 위해 아래의 sortkey_est 함수를 정의함\n",
    "    # sortkey_est 함수는 list 객체의 sort() 함수의 키 값으로 사용되어 정렬 수행\n",
    "    def sortkey_est(pred):\n",
    "        return pred.est\n",
    "    \n",
    "    # sortkey_est() 반환값의 내림 차순으로 정렬 수행하고 top_n개의 최상위 값 추출\n",
    "    predictions.sort(key=sortkey_est, reverse=True)\n",
    "    top_predictions = predictions[:top_n]\n",
    "    \n",
    "    # top_n으로 추출된 영화의 정보 추출\n",
    "    # 영화 아이디, 추천 예상 평점, 제목 추출\n",
    "    top_movie_ids = [int(pred.iid) for pred in top_predictions]\n",
    "    top_movie_rating = [pred.est for pred in top_predictions]\n",
    "    top_movie_titles = movies[movies.movieId.isin(top_movie_ids)]['title']\n",
    "    \n",
    "    top_movie_preds = [(id, title, rating) for id, title, rating in \\\n",
    "                       zip(top_movie_ids, top_movie_titles, top_movie_rating)]\n",
    "    \n",
    "    return top_movie_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화 수 : 46 , 추천 대상 영화 수 : 9696  전체 영화 수 : 9742\n",
      "##### Top-10 추천 영화 리스트 #####\n",
      "Usual Suspects, The (1995) : 4.306302135700814\n",
      "Star Wars: Episode IV - A New Hope (1977) : 4.281663842987387\n",
      "Pulp Fiction (1994) : 4.278152632122759\n",
      "Silence of the Lambs, The (1991) : 4.226073566460876\n",
      "Godfather, The (1972) : 4.1918097904381995\n",
      "Streetcar Named Desire, A (1951) : 4.154746591122658\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) : 4.122016128534504\n",
      "Star Wars: Episode VI - Return of the Jedi (1983) : 4.108009609093436\n",
      "Goodfellas (1990) : 4.083464936588478\n",
      "Glory (1989) : 4.07887165526957\n"
     ]
    }
   ],
   "source": [
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)\n",
    "top_movie_preds = recomm_movie_by_surprise(algo, 9, unseen_movies, top_n=10)\n",
    "\n",
    "print(\"##### Top-10 추천 영화 리스트 #####\")\n",
    "for top_movie in top_movie_preds:\n",
    "    print(top_movie[1], \":\", top_movie[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
