{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 텍스트 분류 실습 - 20 뉴스그룹 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p481(500) ~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런이 내부에 가지고 있는 예제 데이터인 \"20 뉴스그룹 데이터 세트\"를 이용 텍스트 분류 적용.\n",
    "\n",
    "텍스트 분류\n",
    "\n",
    "- 특정 문서의 분류를 학습 데이터를 통해 학습해 모델 생성\n",
    "- 이 학습 모델을 이용해 다른 문서의 분류를 예측\n",
    "\n",
    "사이킷런은 `fetch_20newsgroups()` API를 이용해 뉴스그룹의 분류를 수행해 볼 수 있는 예제 데이터를 제공.\n",
    "\n",
    "텍스트를 피처 벡터화로 변환하면 일반적으로 희소 행렬 형태가 된다.\n",
    "\n",
    "이러한 희소 행렬에 분류를 효과적으로 잘 처리할 수 있는 알고리즘\n",
    "\n",
    "- 로지스틱 회귀\n",
    "- 선형 서포트 벡터 머신\n",
    "- 나이즈 베이즈\n",
    "\n",
    "텍스트를 기반으로 분류를 수행할 때는 먼저 텍스트를 정규화한 뒤 피처 벡터화를 적용.\n",
    "\n",
    "그리고 그 이후에 적합한 머신러닝 알고리즘을 적용해 분류를 학습/예측/평가.\n",
    "\n",
    "이번 절에서는 카운트 기반과 TF-IDF 기반의 벡터화를 차례로 적용해 예측 성능을 비교.\n",
    "\n",
    "피처 벡터화를 위한 파라미터와 `GridSearchCV` 기반의 하이퍼 파라미터 튜닝, 사이킷런의 `Pipeline` 객체를 통해 피처 벡터화 파라미터와 `GridSearchCV` 기반의 하이퍼 파라미터 튜닝을 한꺼번에 하는 방법 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 텍스트 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_data = fetch_20newsgroups(subset='all', random_state=156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fetch_20newsgroups()`는 파이썬 딕셔너리와 유사한 `Bunch` 객체를 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filenames` : `fetch_20newsgroups()` API가 인터넷에서 내려받아 로컬 컴퓨터에 저장하는 디렉터리와 파일명을 지칭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Target` 클래서 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 \n",
      " 0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n",
      "target 클래스의 이름들 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('target 클래스의 값과 분포도 \\n', pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('target 클래스의 이름들 \\n', news_data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Target` 클래스의 값은 0부터 19까지 20개로 구성.\n",
    "\n",
    "개별 데이터가 텍스트로 어떻게 구성돼 있는 지 데이터 한 개만 추출하여 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스그룹 기사의 내용뿐만 아니라 뉴스그룹 제목, 작성자, 소속, 이메일 등의 다양한 정보를 가지고 있음.\n",
    "\n",
    "이 중에서 내용을 제외하고 제목 등의 다른 정보는 제거.  \n",
    "(제목과 소속, 이메일 주소 등의 헤더와 푸터 정보들은 뉴스그룹 분류의 `Target` 클래스 값과 유사한 데이터를 가지고 있는 경우가 많기 때문)\n",
    "\n",
    "`remove` 파라미터를 이용하면 뉴스그룹 기사의 헤더(header), 푸터(footer) 등을 제거할 수 있다.\n",
    "\n",
    "또한 `fetch_20newsgroups()`는 `subset` 파라미터를 이용해 학습 데이터 세트와 테스트 데이터 세트를 분리해 내려받을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기 11314, 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train' 으로 학습용 데이터만 추출\n",
    "# remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "\n",
    "# subset='test' 으로 테스트 데이터만 추출\n",
    "# remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "\n",
    "print('학습 데이터 크기 {0}, 테스트 데이터 크기 {1}'.format(len(train_news.data), len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
    "\n",
    "학습 데이터 : 11,314개의 뉴스그룹 문서 (리스트 형태)  \n",
    "테스트 데이터 : 7,532개의 뉴스그룹 문서 (리스트 형태)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 피처 벡터화\n",
    "\n",
    "`CountVectorizer`를 이용해 학습 데이터의 텍스트를 피처 벡터화 수행\n",
    "\n",
    "테스트 데이터에 대해 피처 벡터화를 수행할 때 유의해야 할 점이 있음\n",
    "  1. 테스트 데이터에서 `CountVectorizer`를 적용할 때는 반드시 **학습 데이터를 이용해 `fit()`이 수행된 `CountVectorizer` 객체를 이용**해 테스트 데이터를 변환(transform)해야 한다.\n",
    "    - 그래야만 학습 시 설정된 `CountVectorizer`의 피처 개수와 테스트 데이터를 `CountVectorizer`로 변환할 피처 개수가 같아진다.\n",
    "    - 테스트 데이터의 피처 벡터화는 학습 데이터에 사용된 `CountVectorizer` 객체 변수인 `cnt_vect.transform()`을 이용해 변환한다.\n",
    "  2. 테스트 데이터 피처 벡터화 시 `fit_transform()`을 사용하면 안됨\n",
    "    - `CountVectorizer.fit_transform()`을 수행하면 테스트 데이터 기반으로 `fit()`, `transform()` 되기 때문에 학습 시 사용된 피처 개수와 예측 시 사용할 피처 개수가 달라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 텍스트의 CountVectorizer Shape:  (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorization으로 피처 벡터화 변환 수행\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(X_train, y_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "\n",
    "# 학습 데이터로 fit()된 CountVecorizer를 이용해 테스트 데이터를 피처 벡터화 변환 수행\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "\n",
    "print(\"학습 데이터 텍스트의 CountVectorizer Shape: \", X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터를 `CountVectorizer`로 피처를 추출한 결과 11,314개의 문서에서 피처, 즉 단어가 101,631개로 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 뉴스 그룹 분류 예측\n",
    "\n",
    "피처 벡터화된 데이터에 로지스틱 회귀를 적용해 뉴스그룹에 대한 분류를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression의 예측 정확도 : 0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mktinfo\\.conda\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LogisticRegression을 이용해 학습/예측/평가 수행\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print(\"CountVectorized Logistic Regression의 예측 정확도 : {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count 기반으로 피처 벡터화가 적용된 데이터 세트에 대한 로지스틱 회귀의 예측 정확도 : 0.606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 TF-IDF 기반 벡터화 및 예측 모델 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression의 예측 정확도 : 0.674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 벡터화를 적용해 학습 데이터 세트와 테스트 데이터 세트 변환\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "# LogisticRegression을 이용해 학습/예측/평가 수행\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print(\"TF-IDF Logistic Regression의 예측 정확도 : {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF가 단순 카운트 기반보다 훨씬 더 높은 예측 정확도(0.674 > 0.606)를 제공함.\n",
    "\n",
    "일반적으로 문서 내에 텍스트가 많고 많은 문서를 가지는 텍스트 분석에는 카운트 벡터화보다는 TF-IDF 벡터화가 좋은 예측 결과를 도출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 텍스트 분석에서 머신러닝 모델 성능 향상 방법 (2가지)\n",
    "\n",
    "1. 최적의 ML 알고리즘을 선택\n",
    "2. 최상의 피처 전처리를 수행\n",
    "  - 텍스트 정규화, Count/TF-IDF 기반 피처 벡터화를 어떻게 효과적으로 적용했는 지가 큰 영향을 미칠 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 TF-IDF 벡터화 하이퍼 파라미터 조정\n",
    "\n",
    "- 스톱워드 : `None` $\\rightarrow$ `english`\n",
    "- `ngram_range` : `(1,1)` $\\rightarrow$ `(1,2)`\n",
    "- `max_df = 300`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression의 예측 정확도 : 0.692\n"
     ]
    }
   ],
   "source": [
    "# stop words 필터링을 추가하고 ngram을 기본 (1,1)에서 (1,2)로 변경해 피처 벡터화 적용\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range=(1,2),\n",
    "                             max_df=300)\n",
    "\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print(\"TF-IDF Vectorized Logistic Regression의 예측 정확도 : {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 정확도 향상 (0.692 > 0.674)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6 `GridSearchCV` 이용 예측 모델 하이퍼 파라미터 최적화\n",
    "\n",
    "로지스틱 회귀의 `C` 파라미터만 변경하면서 최적의 `C`값을 찾은 뒤 이 `C`값으로 학습된 모델에서 테스트 데이터로 예측해 성능을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 폴드 세트로 설정\n",
    "params = {'C': [0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
    "print(\"Logistic Regression best C parameter : \", grid_cv_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀의 `C`가 10일 때 `GridSearchCV`의 교차 검증 테스트 세트에서 가장 좋은 예측 성능을 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 C 값으로 학습된 grid_cv로 예측 및 정확도 평가\n",
    "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print(\"TF-IDF Vectorized Logistic Regression의 예측 정확도 : {0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 테스트 데이터 세트에 적용해 약 0.888(> 0.692)으로 이전보다 약간 향상된 성능 수치가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 사이킷런 파이프라인(`Pipeline`) 사용 및 `GridSearchCV`와의 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
